{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, random_split, DataLoader, Subset\nimport torch.optim as optim\nimport torchvision\nimport torchvision.models as models\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, Subset, random_split\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\nimport random\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T01:44:40.094320Z","iopub.execute_input":"2025-05-06T01:44:40.095227Z","iopub.status.idle":"2025-05-06T01:44:40.102560Z","shell.execute_reply.started":"2025-05-06T01:44:40.095189Z","shell.execute_reply":"2025-05-06T01:44:40.101610Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T01:44:40.103957Z","iopub.execute_input":"2025-05-06T01:44:40.104740Z","iopub.status.idle":"2025-05-06T01:44:40.118520Z","shell.execute_reply.started":"2025-05-06T01:44:40.104715Z","shell.execute_reply":"2025-05-06T01:44:40.117726Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def show(image, label):\n    plt.imshow(image, cmap='gray')  # Use 'gray' since image is in 'L' mode\n    plt.title(f\"Label: {label}\")\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T01:44:40.119361Z","iopub.execute_input":"2025-05-06T01:44:40.119637Z","iopub.status.idle":"2025-05-06T01:44:40.129831Z","shell.execute_reply.started":"2025-05-06T01:44:40.119617Z","shell.execute_reply":"2025-05-06T01:44:40.129118Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/processed-lungs/processed_lungs/labels.csv')\n\nnodule_df = df[df['label'] == 1]\nsecond_df = df[df['label'] == 0]\n\nprint(\"we print nodule \")\nprint(nodule_df)\nprint(\"now second one\")\nprint(second_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T01:44:40.131684Z","iopub.execute_input":"2025-05-06T01:44:40.131933Z","iopub.status.idle":"2025-05-06T01:44:40.260973Z","shell.execute_reply.started":"2025-05-06T01:44:40.131917Z","shell.execute_reply":"2025-05-06T01:44:40.260105Z"}},"outputs":[{"name":"stdout","text":"we print nodule \n                   filename  label\n0     00000004_000_lung.png      1\n1     00000008_002_lung.png      1\n2     00000013_025_lung.png      1\n3     00000017_000_lung.png      1\n4     00000021_000_lung.png      1\n...                     ...    ...\n6326  00030703_001_lung.png      1\n6327  00030715_000_lung.png      1\n6328  00030722_000_lung.png      1\n6329  00030726_000_lung.png      1\n6330  00030793_000_lung.png      1\n\n[6331 rows x 2 columns]\nnow second one\n                     filename  label\n6331    00000001_000_lung.png      0\n6332    00000001_001_lung.png      0\n6333    00000001_002_lung.png      0\n6334    00000002_000_lung.png      0\n6335    00000003_000_lung.png      0\n...                       ...    ...\n112111  00030801_001_lung.png      0\n112112  00030802_000_lung.png      0\n112113  00030803_000_lung.png      0\n112114  00030804_000_lung.png      0\n112115  00030805_000_lung.png      0\n\n[105785 rows x 2 columns]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"BATCH_SIZE = 8\nLR = 0.001\nEPOCHS = 10\n\nmain_dest_dir = '/kaggle/working/'\nsource_base_dir = '/kaggle/input/processed-lungs'\n\nclass ChestXRayDataset(Dataset):\n    def __init__(self):\n        self.image_paths = []\n        self.labels = []\n        self.normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                     \n        self.transform_positive = transforms.Compose([\n            transforms.Resize(224),\n            transforms.ToTensor(),\n            self.normalize\n        ])\n        \n        self.transform_negative = transforms.Compose([\n            transforms.Resize(224),\n            transforms.ToTensor(),\n            self.normalize\n        ])\n        \n        for cohort_df, label_value in [(nodule_df, 1.0), (second_df, 0.0)]:\n            source_folder = 'processed_lungs/nodule' if label_value == 1 else 'processed_lungs/non_nodule'\n            for _, row in cohort_df.iterrows():\n                image_filename = row['filename']\n                img_path = os.path.join(source_base_dir,\n                                        source_folder,\n                                        image_filename)\n        \n                self.image_paths.append(img_path)\n                self.labels.append(label_value)\n\n    def __getitem__(self, index):\n        img_path = self.image_paths[index]\n        label = self.labels[index]\n        image = Image.open(img_path).convert('RGB')\n        if label == 1.0:\n            image = self.transform_positive(image)\n        else:\n            image = self.transform_negative(image)\n            \n        return image, torch.tensor(label, dtype=torch.float32)\n\n    def __len__(self):\n        return len(self.image_paths)\n        \n    def tackle_idxs(self, idxs):\n        image_paths_temp = []\n        labels_temp = []\n        \n        for i in idxs:\n            label = self.labels[i]\n            img_path = self.image_paths[i]\n            \n            image_paths_temp.append(img_path)\n            labels_temp.append(label)\n        \n        combined = list(zip(image_paths_temp, labels_temp))\n        random.shuffle(combined)\n        self.image_paths, self.labels = map(list, zip(*combined))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T01:44:40.261735Z","iopub.execute_input":"2025-05-06T01:44:40.261964Z","iopub.status.idle":"2025-05-06T01:44:40.271559Z","shell.execute_reply.started":"2025-05-06T01:44:40.261946Z","shell.execute_reply":"2025-05-06T01:44:40.270879Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class AlexNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.alexnet = models.alexnet(weights='IMAGENET1K_V1')\n        \n        for param in self.alexnet.parameters():\n            param.requires_grad = False\n\n        for name, param in self.alexnet.named_parameters():\n            if name.startswith(\"classifier\"):\n                param.requires_grad = True\n\n        num_ftrs = self.alexnet.classifier[6].in_features\n        self.alexnet.classifier[6] = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_ftrs, 256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, 1)\n        )\n\n    def forward(self, x):\n        return self.alexnet(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T01:44:40.272116Z","iopub.execute_input":"2025-05-06T01:44:40.272364Z","iopub.status.idle":"2025-05-06T01:44:40.288150Z","shell.execute_reply.started":"2025-05-06T01:44:40.272343Z","shell.execute_reply":"2025-05-06T01:44:40.287281Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"dataset_all = ChestXRayDataset()\nloader_all = DataLoader(dataset_all, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n\nmodel = AlexNet().to(device)\ncheckpoint = torch.load(\"/kaggle/input/alexnet_final_model_new1-2/pytorch/default/1/AlexNet_final_model_new1 (2).pth\", map_location=device)\nmodel.load_state_dict(checkpoint)\nmodel.eval()\n\nall_labels = []\nall_preds = []\nall_probs = []\n\nwith torch.no_grad():\n    for imgs, labels in loader_all:\n        imgs = imgs.to(device)\n        labels = labels.to(device)\n        logits = model(imgs).view(-1)\n        probs = torch.sigmoid(logits)\n        preds = (probs >= 0.5).float()\n        print(preds)\n        all_labels.extend(labels.cpu().numpy())\n        all_probs.extend(probs.cpu().numpy())\n        all_preds.extend(preds.cpu().numpy())\n\naccuracy  = accuracy_score(all_labels, all_preds)\nprecision = precision_score(all_labels, all_preds, zero_division=0)\nrecall    = recall_score(all_labels, all_preds, zero_division=0)\nf1        = f1_score(all_labels, all_preds, zero_division=0)\nauc       = roc_auc_score(all_labels, all_probs)\nfpr, tpr, _ = roc_curve(all_labels, all_probs)\n\nprint(\"===== Full-Dataset Evaluation =====\")\nprint(f\"Samples: {len(dataset_all)}\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(f\"ROC AUC  : {auc:.4f}\")\n\nplt.figure()\nplt.plot(fpr, tpr, label=f'ROC AUC = {auc:.4f}')\nplt.plot([0,1], [0,1], '--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve â€” Full Dataset')\nplt.legend(loc='lower right')\nplt.savefig('AlexNet_full_dataset_roc.png')\nplt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
